# Consignia: 
Se requiere construir un modelo que sea capaz de predecir, dados los datos de s铆ntomas de un paciente, si es posible o no que este sufra de alguna enfermedad. Esto se requiere tanto para enfermedades comunes (muchos datos) como para enfermedades hu茅rfanas (pocos datos). 

Para el problema anterior, proponga un pipeline de ML en donde describa, de manera general, el proceso completo end-to-end para el desarrollo del modelo requerido.

Considerando el mismo problema, se necesita desarrollar un servicio que permita a un m茅dico usar el modelo para obtener una respuesta

### 锔 Nota importante

Parte de este trabajo ser谩 reutilizado en mi proyecto de grado, enfocado en la clasificaci贸n de **tumores cerebrales**.  
- Para la **primera entrega**, se consideraron 煤nicamente dos categor铆as: `HIGH GRADE` y `LOW GRADE`.
- En esta **segunda entrega**, se ampli贸 a **cuatro categor铆as**:
  - `LOW GRADE de primer grado`
  - `LOW GRADE de segundo grado`.
  - `HIGH GRADE de tercer grado`
  - `HIGH GRADE de cuarto grado`

---

# Guia de uso:

## Instalacion 

1. Instalar Docker. 
Es necesario instalar docker ya que esta es la herramienta que facilitara al usuario desplegar el sistema de manera automatizada sin depender de un profesional.

recurso: https://docs.docker.com/engine/install/

2. Lanzar el sistema

Estando en la carpeta root del proyecto, abra una terminal y ejecute el comando: docker-compose up -d 

Posterior a esto, se desplegaran automaticamente las aplicaciones de front y back-end.


## Uso del producto

Entrar en el navegador a http://127.0.0.1:5000 para conectarse a la web app. 

En esta encontrara 2 opciones posibles: 

* clasificar un archivo CSV: importar un archivo de datos radiomicos de un tumor cerebral con el fin de clasificar su grado de malignidad. Al presionar el boton de clasificar archivo, se mostrara la prediccion del modelo en pantalla.
    * (El modelo no es mas que una funcion y para que esta funcione es necesario usar los archivos proporcionados en la carpeta data.)
* Obtener ultimas predicciones: Al presionar el bnoton obtener, se mostrara en pantalla una lista con las ultimas 5 predicciones registradas.

---

# Pipeline propuesto

### 1. Data Input

- Se reciben archivos generados a partir de la extracci贸n de datos radi贸micos de im谩genes de resonancia magn茅tica cerebral.
- Estos archivos son entregados por la cl铆nica directamente al equipo t茅cnico responsable.
- Posteriormente, se alojan en un bucket para que sean accesibles tanto para el pipeline como para el resto del equipo de desarrollo.  
  > Propuesta: **AWS S3**


### 2. Data Processing

- Los archivos se reformatean para poder tratarlos como registros en una tabla estructurada.
- Se realiza un an谩lisis exploratorio de los datos, generando un reporte con estad铆sticas descriptivas relevantes del dataset.
- Si se detecta desbalanceo entre clases, se aplica **oversampling** a la clase minoritaria.
- Se preparan los datos mediante:
  - Normalizaci贸n de caracter铆sticas.
  - Detecci贸n y tratamiento de outliers.
  - Reduccion de dimensionalidad
  - feature extraction
  - Gestion de variables categoricas
  - Divisiones en conjuntos de entrenamiento y prueba.


### 3. Model Iterations

- Se entrenan tres modelos:
  - **XGBoost**
  - **Random Forest**
  - **SVM**
- Todos los modelos utilizan **validaci贸n cruzada (cross-validation)**.
- Se realiza una b煤squeda de hiperpar谩metros para cada modelo con el fin de optimizar su desempe帽o.
- Se eval煤an m茅tricas clave como:
  - Precisi贸n
  - Recall
  - F1-score
  - AUC



### 4. Model Selection

- Se selecciona el modelo con mejor desempe帽o en las m茅tricas clave, priorizando **precisi贸n** y **recall**, dado el contexto cl铆nico.
- El modelo seleccionado es validado de acuerdo con los est谩ndares de calidad establecidos por la cl铆nica colaboradora.


### 5. Model Deployment

- Se desarrollan y despliegan dos componentes:
  - Un **frontend** en forma de aplicaci贸n web para interacci贸n con m茅dicos y personal de salud.
  - Un **backend** que expone una **API** encargada de cargar el modelo entrenado y realizar predicciones bajo demanda.
- El sistema completo se ejecuta en contenedores mediante `docker-compose` para facilitar su instalaci贸n.



### 6. Model Predictions

- El usuario accede a la aplicaci贸n web, carga un archivo y solicita una predicci贸n.
- La predicci贸n es procesada por el modelo alojado en el backend.
- Las predicciones son almacenadas autom谩ticamente en una base de datos relacional para su consulta futura.  
  >  Propuesta: **AWS RDS**
